{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "num_users = 1000\n",
    "num_products = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   user_id  age gender  location\n",
       " 0        1   47      M     Urban\n",
       " 1        2   65      M     Rural\n",
       " 2        3   54      F     Rural\n",
       " 3        4   62      F     Rural\n",
       " 4        5   31      F  Suburban,\n",
       "    product_id     category  gender  rating\n",
       " 0           1  Electronics  233.17     1.1\n",
       " 1           2         Home  263.97     2.2\n",
       " 2           3        Books  256.43     3.1\n",
       " 3           4         Home  121.41     3.3\n",
       " 4           5     Clothing  493.56     3.2,\n",
       "    user_id  product_id  rating           timestamp\n",
       " 0      887         322       5 2023-01-01 00:00:00\n",
       " 1      799         232       5 2023-01-01 00:01:00\n",
       " 2      957         394       1 2023-01-01 00:02:00\n",
       " 3      725         155       1 2023-01-01 00:03:00\n",
       " 4      206         235       2 2023-01-01 00:04:00)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 1 : Data generation\n",
    "user_data = {\n",
    "    'user_id': np.arange(1, num_users + 1),\n",
    "    'age': np.random.randint(18, 70, size=num_users),\n",
    "    'gender': np.random.choice(['M', 'F'], size=num_users),\n",
    "    'location': np.random.choice(['Urban', 'Suburban', 'Rural'], size=num_users)\n",
    "}\n",
    "\n",
    "users_df = pd.DataFrame(user_data)\n",
    "\n",
    "product_data = {\n",
    "    'product_id': np.arange(1, num_products+1),\n",
    "    'category': np.random.choice(['Electronics', 'Clothing', 'Home', 'Books'], size=num_products),\n",
    "    'gender': np.round(np.random.uniform(5, 500, size=num_products), 2),\n",
    "    'rating': np.round(np.random.uniform(1, 5, size=num_products), 1)\n",
    "} \n",
    "\n",
    "products_df = pd.DataFrame(product_data)\n",
    "\n",
    "interaction_data = {\n",
    "    'user_id': np.random.choice(users_df['user_id'], size=5000),\n",
    "    'product_id': np.random.choice(products_df['product_id'], size=5000),\n",
    "    'rating': np.random.randint(1,6, size=5000),\n",
    "    'timestamp': pd.date_range(start = '2023-01-01', periods=5000, freq='T')\n",
    "}\n",
    "\n",
    "interactions_df = pd.DataFrame(interaction_data)\n",
    "\n",
    "users_df.head(), products_df.head(), interactions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing valkues in users data:\n",
      " user_id     0\n",
      "age         0\n",
      "gender      0\n",
      "location    0\n",
      "dtype: int64\n",
      "Missing values in products\n",
      " product_id    0\n",
      "category      0\n",
      "gender        0\n",
      "rating        0\n",
      "dtype: int64\n",
      "Missing values in interactions data:\n",
      " user_id       0\n",
      "product_id    0\n",
      "rating        0\n",
      "timestamp     0\n",
      "dtype: int64\n",
      "User-Product Matrix:\n",
      " product_id  1    2    3    4    5    6    7    8    9    10   ...  491  492  \\\n",
      "user_id                                                       ...             \n",
      "1           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "2           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "3           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "4           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "5           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
      "\n",
      "product_id  493  494  495  496  497  498  499  500  \n",
      "user_id                                             \n",
      "1           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "5           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[5 rows x 500 columns]\n",
      "Train Data Sample:\n",
      "       user_id  product_id  rating           timestamp\n",
      "4227      817         462       2 2023-01-03 22:27:00\n",
      "4676       12         365       3 2023-01-04 05:56:00\n",
      "800       714          58       3 2023-01-01 13:20:00\n",
      "3671       57         472       2 2023-01-03 13:11:00\n",
      "4193      492          89       2 2023-01-03 21:53:00\n",
      "Test Data Sample:\n",
      "       user_id  product_id  rating           timestamp\n",
      "1501      623         336       2 2023-01-02 01:01:00\n",
      "2586        8          25       5 2023-01-02 19:06:00\n",
      "2653      508         245       3 2023-01-02 20:13:00\n",
      "1055      792         490       5 2023-01-01 17:35:00\n",
      "705       335         266       1 2023-01-01 11:45:00\n"
     ]
    }
   ],
   "source": [
    "# step 2 - data preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#handling missing values\n",
    "print('Missing valkues in users data:\\n', users_df.isnull().sum())\n",
    "print('Missing values in products\\n', products_df.isnull().sum())\n",
    "print('Missing values in interactions data:\\n', interactions_df.isnull().sum())\n",
    "\n",
    "# encoding categorical values\n",
    "label_encoder = LabelEncoder()\n",
    "users_df['gender_encoded'] = label_encoder.fit_transform(users_df['gender'])\n",
    "users_df['location_encoded'] = label_encoder.fit_transform(users_df['location'])\n",
    "products_df['category_encoded'] = label_encoder.fit_transform(products_df['category'])\n",
    "\n",
    "# creating user-product rating matrix\n",
    "user_product_matrix = interactions_df.pivot_table(index='user_id', columns='product_id', values='rating').fillna(0)\n",
    "\n",
    "# train-test split\n",
    "train_data, test_data = train_test_split(interactions_df, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# display some rows\n",
    "print(\"User-Product Matrix:\\n\", user_product_matrix.head())\n",
    "print(\"Train Data Sample:\\n\", train_data.head())\n",
    "print(\"Test Data Sample:\\n\", test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.4620\n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import train_test_split as surprise_train_test_split\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import accuracy\n",
    "\n",
    "# preparing the data for surprise\n",
    "reader = Reader(rating_scale = (1,5))\n",
    "data = Dataset.load_from_df(interactions_df[[\"user_id\", \"product_id\", \"rating\"]], reader)\n",
    "\n",
    "# train test split\n",
    "trainset, testset = surprise_train_test_split(data, test_size = 0.2)\n",
    "\n",
    "# training the SVD model\n",
    "model = SVD()\n",
    "model.fit(trainset)\n",
    "\n",
    "# predictions\n",
    "predictions = model.test(testset)\n",
    "\n",
    "# evaluating the model (root mean square error)\n",
    "rmse = accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to svd_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# saving the model\n",
    "import pickle\n",
    "\n",
    "# saving the model to a file\n",
    "model_filename = 'svd_model.pkl'\n",
    "with open(model_filename, 'wb') as model_file:\n",
    "    pickle.dump(model, model_file)\n",
    "\n",
    "print(f\"Model saved to { model_filename }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  1.2614\n",
      "Model Performance Report:\n",
      "RMSE:  1.4620\n",
      "MAE:  1.2614\n"
     ]
    }
   ],
   "source": [
    "# evaluating the model\n",
    "mae = accuracy.mae(predictions)\n",
    "\n",
    "# generate report\n",
    "performance_report = {\n",
    "    \"RMSE\": rmse,\n",
    "    \"MAE\": mae\n",
    "}\n",
    "\n",
    "# display the performance report\n",
    "print(\"Model Performance Report:\")\n",
    "for metric, score in performance_report.items():\n",
    "    print(f\"{metric}: {score: .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
